{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('maybe_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    assuming acceleration of to but in a comfortab...\n",
       "1    is capable of transporting satellite to orbit ...\n",
       "2                                                  yup\n",
       "3                                                 part\n",
       "4    fly to most place on earth in under min and an...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tweet[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tweet = test.tweet.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 3000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(test['tweet'].values)\n",
    "X = tokenizer.texts_to_sequences(test['tweet'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 28, 128)           384000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 591       \n",
      "=================================================================\n",
      "Total params: 639,391\n",
      "Trainable params: 639,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1761, 28) (1761, 3)\n",
      "(441, 28) (441, 3)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(test['signal_x']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1584 samples, validate on 177 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 1.0883 - acc: 0.3946 - val_loss: 1.0911 - val_acc: 0.3842\n",
      "Epoch 2/20\n",
      " - 2s - loss: 1.0644 - acc: 0.4249 - val_loss: 1.0815 - val_acc: 0.3898\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.9799 - acc: 0.5417 - val_loss: 1.0748 - val_acc: 0.4859\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.8039 - acc: 0.6679 - val_loss: 1.1540 - val_acc: 0.4294\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6370 - acc: 0.7487 - val_loss: 1.2890 - val_acc: 0.4463\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.5000 - acc: 0.8043 - val_loss: 1.5953 - val_acc: 0.4350\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.3966 - acc: 0.8472 - val_loss: 1.6626 - val_acc: 0.4181\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.3237 - acc: 0.8794 - val_loss: 1.8014 - val_acc: 0.4068\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.3109 - acc: 0.8807 - val_loss: 2.0110 - val_acc: 0.3785\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.2364 - acc: 0.9066 - val_loss: 1.9642 - val_acc: 0.4237\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.2060 - acc: 0.9129 - val_loss: 2.3607 - val_acc: 0.4181\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.2094 - acc: 0.9104 - val_loss: 2.4860 - val_acc: 0.4124\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.1834 - acc: 0.9274 - val_loss: 2.3880 - val_acc: 0.4068\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1603 - acc: 0.9343 - val_loss: 2.6562 - val_acc: 0.4294\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1351 - acc: 0.9463 - val_loss: 2.8938 - val_acc: 0.4124\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.1423 - acc: 0.9407 - val_loss: 3.0443 - val_acc: 0.4407\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.1405 - acc: 0.9444 - val_loss: 3.0445 - val_acc: 0.3842\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.1322 - acc: 0.9438 - val_loss: 2.9582 - val_acc: 0.4011\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.1198 - acc: 0.9501 - val_loss: 3.3623 - val_acc: 0.3955\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.1153 - acc: 0.9451 - val_loss: 3.0546 - val_acc: 0.3898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a33f19780>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_split=0.1, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 3.30\n",
      "acc: 0.32\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = 32)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, SpatialDropout1D, SimpleRNN\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D, RNN\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('updated_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_from</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>encoded_sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_30</th>\n",
       "      <th>pc_31</th>\n",
       "      <th>pc_32</th>\n",
       "      <th>pc_33</th>\n",
       "      <th>pc_34</th>\n",
       "      <th>pc_35</th>\n",
       "      <th>pc_36</th>\n",
       "      <th>pc_37</th>\n",
       "      <th>pc_38</th>\n",
       "      <th>signal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>assuming acceleration of to but in a comfortab...</td>\n",
       "      <td>-0.031750</td>\n",
       "      <td>-0.028850</td>\n",
       "      <td>-0.030290</td>\n",
       "      <td>-0.018736</td>\n",
       "      <td>-0.060675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.045822</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.100572</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>0.035932</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>is capable of transporting satellite to orbit ...</td>\n",
       "      <td>-0.059331</td>\n",
       "      <td>-0.099826</td>\n",
       "      <td>-0.154772</td>\n",
       "      <td>-0.040355</td>\n",
       "      <td>0.072285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>-0.019813</td>\n",
       "      <td>-0.035809</td>\n",
       "      <td>-0.034079</td>\n",
       "      <td>-0.014687</td>\n",
       "      <td>-0.008986</td>\n",
       "      <td>-0.019845</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yup</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>0.069531</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>-0.037774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>0.065735</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>-0.021751</td>\n",
       "      <td>-0.014138</td>\n",
       "      <td>-0.037047</td>\n",
       "      <td>-0.050031</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>part</td>\n",
       "      <td>-0.005050</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.016279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009052</td>\n",
       "      <td>-0.008601</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.007619</td>\n",
       "      <td>-0.005289</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>-0.011967</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>fly to most place on earth in under min and an...</td>\n",
       "      <td>-0.031167</td>\n",
       "      <td>-0.027725</td>\n",
       "      <td>-0.012331</td>\n",
       "      <td>-0.039909</td>\n",
       "      <td>-0.070462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>-0.039462</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>-0.012277</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>0.040576</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   retweet_from  tweet_length  encoded_sentiment  polarity  \\\n",
       "0           171           105                  1  0.366667   \n",
       "1            77           113                  1  0.200000   \n",
       "2           171             6                  0  0.000000   \n",
       "3           171             7                  0  0.000000   \n",
       "4           171            96                  1  0.650000   \n",
       "\n",
       "                                               tweet      pc_1      pc_2  \\\n",
       "0  assuming acceleration of to but in a comfortab... -0.031750 -0.028850   \n",
       "1  is capable of transporting satellite to orbit ... -0.059331 -0.099826   \n",
       "2                                                yup -0.002330  0.033983   \n",
       "3                                               part -0.005050  0.024117   \n",
       "4  fly to most place on earth in under min and an... -0.031167 -0.027725   \n",
       "\n",
       "       pc_3      pc_4      pc_5    ...        pc_30     pc_31     pc_32  \\\n",
       "0 -0.030290 -0.018736 -0.060675    ...     0.017885  0.045822 -0.006862   \n",
       "1 -0.154772 -0.040355  0.072285    ...    -0.011667  0.003882  0.018002   \n",
       "2  0.069531 -0.014177 -0.037774    ...     0.015722 -0.025726  0.065735   \n",
       "3  0.043362 -0.001804 -0.016279    ...    -0.009052 -0.008601  0.001285   \n",
       "4 -0.012331 -0.039909 -0.070462    ...     0.020042  0.030526 -0.039462   \n",
       "\n",
       "      pc_33     pc_34     pc_35     pc_36     pc_37     pc_38  signal_y  \n",
       "0 -0.012954 -0.005468 -0.100572 -0.029374  0.041363  0.035932      stay  \n",
       "1 -0.019813 -0.035809 -0.034079 -0.014687 -0.008986 -0.019845      stay  \n",
       "2  0.041686 -0.021751 -0.014138 -0.037047 -0.050031 -0.084722      stay  \n",
       "3 -0.007619 -0.005289 -0.025700 -0.008989 -0.011967 -0.004665      stay  \n",
       "4  0.088186 -0.012277  0.033849  0.040576  0.051975 -0.031236      stay  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    assuming acceleration of to but in a comfortab...\n",
       "1    is capable of transporting satellite to orbit ...\n",
       "2                                                  yup\n",
       "3                                                 part\n",
       "4    fly to most place on earth in under min and an...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tweet[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tweet = test.tweet.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 44\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(test['tweet'].values)\n",
    "X = tokenizer.texts_to_sequences(test['tweet'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 128)           5632      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 3)                 591       \n",
      "=================================================================\n",
      "Total params: 261,023\n",
      "Trainable params: 261,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2564, 15) (2564, 3)\n",
      "(641, 15) (641, 3)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(test['signal_y']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2307 samples, validate on 257 samples\n",
      "Epoch 1/200\n",
      "2307/2307 [==============================] - 5s 2ms/step - loss: 1.0888 - acc: 0.4053 - val_loss: 1.0902 - val_acc: 0.4047\n",
      "Epoch 2/200\n",
      "2307/2307 [==============================] - 2s 875us/step - loss: 1.0823 - acc: 0.4148 - val_loss: 1.0919 - val_acc: 0.3969\n",
      "Epoch 3/200\n",
      "2307/2307 [==============================] - 2s 896us/step - loss: 1.0743 - acc: 0.4278 - val_loss: 1.1062 - val_acc: 0.3813\n",
      "Epoch 4/200\n",
      "2307/2307 [==============================] - 2s 898us/step - loss: 1.0695 - acc: 0.4300 - val_loss: 1.1072 - val_acc: 0.3619\n",
      "Epoch 5/200\n",
      "2307/2307 [==============================] - 2s 899us/step - loss: 1.0656 - acc: 0.4348 - val_loss: 1.1099 - val_acc: 0.3619\n",
      "Epoch 6/200\n",
      "2307/2307 [==============================] - 2s 900us/step - loss: 1.0647 - acc: 0.4408 - val_loss: 1.1092 - val_acc: 0.3658\n",
      "Epoch 7/200\n",
      "2307/2307 [==============================] - 2s 942us/step - loss: 1.0600 - acc: 0.4361 - val_loss: 1.1158 - val_acc: 0.3541\n",
      "Epoch 8/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 1.0562 - acc: 0.4335 - val_loss: 1.1199 - val_acc: 0.3268\n",
      "Epoch 9/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.0549 - acc: 0.4517 - val_loss: 1.1357 - val_acc: 0.3463\n",
      "Epoch 10/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 1.0586 - acc: 0.4391 - val_loss: 1.1228 - val_acc: 0.3463\n",
      "Epoch 11/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 1.0503 - acc: 0.4439 - val_loss: 1.1255 - val_acc: 0.3463\n",
      "Epoch 12/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.0479 - acc: 0.4482 - val_loss: 1.1174 - val_acc: 0.3346\n",
      "Epoch 13/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.0495 - acc: 0.4521 - val_loss: 1.1203 - val_acc: 0.3619\n",
      "Epoch 14/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 1.0407 - acc: 0.4577 - val_loss: 1.1327 - val_acc: 0.3580\n",
      "Epoch 15/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.0401 - acc: 0.4538 - val_loss: 1.1302 - val_acc: 0.3541\n",
      "Epoch 16/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.0379 - acc: 0.4577 - val_loss: 1.1410 - val_acc: 0.3658\n",
      "Epoch 17/200\n",
      "2307/2307 [==============================] - 2s 945us/step - loss: 1.0321 - acc: 0.4642 - val_loss: 1.1278 - val_acc: 0.3813\n",
      "Epoch 18/200\n",
      "2307/2307 [==============================] - 2s 912us/step - loss: 1.0343 - acc: 0.4521 - val_loss: 1.1385 - val_acc: 0.3891\n",
      "Epoch 19/200\n",
      "2307/2307 [==============================] - 2s 937us/step - loss: 1.0269 - acc: 0.4690 - val_loss: 1.1487 - val_acc: 0.3852\n",
      "Epoch 20/200\n",
      "2307/2307 [==============================] - 2s 988us/step - loss: 1.0231 - acc: 0.4668 - val_loss: 1.1402 - val_acc: 0.3580\n",
      "Epoch 21/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 1.0146 - acc: 0.4703 - val_loss: 1.1596 - val_acc: 0.3385\n",
      "Epoch 22/200\n",
      "2307/2307 [==============================] - 2s 942us/step - loss: 1.0189 - acc: 0.4755 - val_loss: 1.1649 - val_acc: 0.3385\n",
      "Epoch 23/200\n",
      "2307/2307 [==============================] - 2s 927us/step - loss: 1.0090 - acc: 0.4642 - val_loss: 1.1712 - val_acc: 0.3346\n",
      "Epoch 24/200\n",
      "2307/2307 [==============================] - 2s 931us/step - loss: 1.0044 - acc: 0.4907 - val_loss: 1.1590 - val_acc: 0.3307\n",
      "Epoch 25/200\n",
      "2307/2307 [==============================] - 2s 937us/step - loss: 0.9978 - acc: 0.4924 - val_loss: 1.2087 - val_acc: 0.3268\n",
      "Epoch 26/200\n",
      "2307/2307 [==============================] - 2s 961us/step - loss: 0.9896 - acc: 0.4855 - val_loss: 1.1897 - val_acc: 0.3307\n",
      "Epoch 27/200\n",
      "2307/2307 [==============================] - 2s 983us/step - loss: 0.9794 - acc: 0.4980 - val_loss: 1.1996 - val_acc: 0.3268\n",
      "Epoch 28/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.9708 - acc: 0.4946 - val_loss: 1.1925 - val_acc: 0.3463\n",
      "Epoch 29/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.9556 - acc: 0.5193 - val_loss: 1.2323 - val_acc: 0.3385\n",
      "Epoch 30/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.9470 - acc: 0.5245 - val_loss: 1.2659 - val_acc: 0.3307\n",
      "Epoch 31/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.9376 - acc: 0.5267 - val_loss: 1.2901 - val_acc: 0.3113\n",
      "Epoch 32/200\n",
      "2307/2307 [==============================] - 2s 948us/step - loss: 0.9272 - acc: 0.5401 - val_loss: 1.2716 - val_acc: 0.3307\n",
      "Epoch 33/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.9153 - acc: 0.5319 - val_loss: 1.2504 - val_acc: 0.3346\n",
      "Epoch 34/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.8955 - acc: 0.5648 - val_loss: 1.2913 - val_acc: 0.3385\n",
      "Epoch 35/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.8829 - acc: 0.5544 - val_loss: 1.3272 - val_acc: 0.3385\n",
      "Epoch 36/200\n",
      "2307/2307 [==============================] - 2s 955us/step - loss: 0.8691 - acc: 0.5674 - val_loss: 1.3415 - val_acc: 0.3074\n",
      "Epoch 37/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.8590 - acc: 0.5821 - val_loss: 1.3330 - val_acc: 0.3307\n",
      "Epoch 38/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.8392 - acc: 0.5917 - val_loss: 1.4003 - val_acc: 0.3230\n",
      "Epoch 39/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.8170 - acc: 0.6068 - val_loss: 1.4085 - val_acc: 0.3268\n",
      "Epoch 40/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.8125 - acc: 0.6042 - val_loss: 1.3801 - val_acc: 0.3035\n",
      "Epoch 41/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.7890 - acc: 0.6160 - val_loss: 1.3999 - val_acc: 0.2957\n",
      "Epoch 42/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.7796 - acc: 0.6277 - val_loss: 1.4729 - val_acc: 0.3230\n",
      "Epoch 43/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.7672 - acc: 0.6342 - val_loss: 1.4616 - val_acc: 0.3113\n",
      "Epoch 44/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.7479 - acc: 0.6381 - val_loss: 1.4895 - val_acc: 0.2957\n",
      "Epoch 45/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.7368 - acc: 0.6550 - val_loss: 1.5983 - val_acc: 0.3230\n",
      "Epoch 46/200\n",
      "2307/2307 [==============================] - 2s 1000us/step - loss: 0.7199 - acc: 0.6580 - val_loss: 1.5415 - val_acc: 0.3424\n",
      "Epoch 47/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.6910 - acc: 0.6784 - val_loss: 1.6231 - val_acc: 0.3346\n",
      "Epoch 48/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.6775 - acc: 0.6849 - val_loss: 1.6061 - val_acc: 0.3424\n",
      "Epoch 49/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.6535 - acc: 0.6944 - val_loss: 1.6514 - val_acc: 0.3152\n",
      "Epoch 50/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.6538 - acc: 0.6779 - val_loss: 1.6813 - val_acc: 0.3385\n",
      "Epoch 51/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.6192 - acc: 0.7109 - val_loss: 1.7284 - val_acc: 0.3424\n",
      "Epoch 52/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.6230 - acc: 0.7091 - val_loss: 1.7476 - val_acc: 0.3113\n",
      "Epoch 53/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.6054 - acc: 0.7200 - val_loss: 1.7031 - val_acc: 0.3385\n",
      "Epoch 54/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.6049 - acc: 0.7221 - val_loss: 1.7508 - val_acc: 0.3230\n",
      "Epoch 55/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.5722 - acc: 0.7347 - val_loss: 1.7834 - val_acc: 0.3385\n",
      "Epoch 56/200\n",
      "2307/2307 [==============================] - 2s 985us/step - loss: 0.5654 - acc: 0.7434 - val_loss: 1.7989 - val_acc: 0.3541\n",
      "Epoch 57/200\n",
      "2307/2307 [==============================] - 2s 962us/step - loss: 0.5536 - acc: 0.7421 - val_loss: 1.8409 - val_acc: 0.3268\n",
      "Epoch 58/200\n",
      "2307/2307 [==============================] - 2s 961us/step - loss: 0.5340 - acc: 0.7529 - val_loss: 1.9004 - val_acc: 0.3191\n",
      "Epoch 59/200\n",
      "2307/2307 [==============================] - 2s 963us/step - loss: 0.5120 - acc: 0.7655 - val_loss: 1.8836 - val_acc: 0.3191\n",
      "Epoch 60/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.5177 - acc: 0.7551 - val_loss: 1.8691 - val_acc: 0.3230\n",
      "Epoch 61/200\n",
      "2307/2307 [==============================] - 2s 878us/step - loss: 0.5101 - acc: 0.7616 - val_loss: 1.9515 - val_acc: 0.3346\n",
      "Epoch 62/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.5072 - acc: 0.7690 - val_loss: 1.8107 - val_acc: 0.3424\n",
      "Epoch 63/200\n",
      "2307/2307 [==============================] - 2s 897us/step - loss: 0.4976 - acc: 0.7694 - val_loss: 1.9193 - val_acc: 0.3502\n",
      "Epoch 64/200\n",
      "2307/2307 [==============================] - 2s 882us/step - loss: 0.4982 - acc: 0.7685 - val_loss: 1.9448 - val_acc: 0.3463\n",
      "Epoch 65/200\n",
      "2307/2307 [==============================] - 2s 922us/step - loss: 0.4708 - acc: 0.7789 - val_loss: 1.9349 - val_acc: 0.3268\n",
      "Epoch 66/200\n",
      "2307/2307 [==============================] - 2s 903us/step - loss: 0.4629 - acc: 0.7928 - val_loss: 1.9516 - val_acc: 0.3580\n",
      "Epoch 67/200\n",
      "2307/2307 [==============================] - 2s 893us/step - loss: 0.4553 - acc: 0.7902 - val_loss: 2.0360 - val_acc: 0.3385\n",
      "Epoch 68/200\n",
      "2307/2307 [==============================] - 2s 911us/step - loss: 0.4524 - acc: 0.7876 - val_loss: 2.0505 - val_acc: 0.3230\n",
      "Epoch 69/200\n",
      "2307/2307 [==============================] - 2s 897us/step - loss: 0.4360 - acc: 0.7958 - val_loss: 2.0760 - val_acc: 0.3346\n",
      "Epoch 70/200\n",
      "2307/2307 [==============================] - 2s 898us/step - loss: 0.4380 - acc: 0.8049 - val_loss: 2.1639 - val_acc: 0.3152\n",
      "Epoch 71/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.4399 - acc: 0.7950 - val_loss: 2.1782 - val_acc: 0.3074\n",
      "Epoch 72/200\n",
      "2307/2307 [==============================] - 2s 922us/step - loss: 0.4292 - acc: 0.7980 - val_loss: 2.1695 - val_acc: 0.3152\n",
      "Epoch 73/200\n",
      "2307/2307 [==============================] - 2s 901us/step - loss: 0.4156 - acc: 0.8088 - val_loss: 2.2422 - val_acc: 0.3074\n",
      "Epoch 74/200\n",
      "2307/2307 [==============================] - 2s 913us/step - loss: 0.4063 - acc: 0.8158 - val_loss: 2.2398 - val_acc: 0.3268\n",
      "Epoch 75/200\n",
      "2307/2307 [==============================] - 2s 894us/step - loss: 0.3942 - acc: 0.8301 - val_loss: 2.2649 - val_acc: 0.3424\n",
      "Epoch 76/200\n",
      "2307/2307 [==============================] - 2s 900us/step - loss: 0.3999 - acc: 0.8171 - val_loss: 2.2403 - val_acc: 0.3268\n",
      "Epoch 77/200\n",
      "2307/2307 [==============================] - 2s 893us/step - loss: 0.3932 - acc: 0.8192 - val_loss: 2.3045 - val_acc: 0.3424\n",
      "Epoch 78/200\n",
      "2307/2307 [==============================] - 2s 907us/step - loss: 0.3879 - acc: 0.8253 - val_loss: 2.2718 - val_acc: 0.3541\n",
      "Epoch 79/200\n",
      "2307/2307 [==============================] - 2s 910us/step - loss: 0.3860 - acc: 0.8210 - val_loss: 2.3374 - val_acc: 0.3541\n",
      "Epoch 80/200\n",
      "2307/2307 [==============================] - 2s 954us/step - loss: 0.3768 - acc: 0.8253 - val_loss: 2.2972 - val_acc: 0.3580\n",
      "Epoch 81/200\n",
      "2307/2307 [==============================] - 2s 909us/step - loss: 0.3664 - acc: 0.8266 - val_loss: 2.2807 - val_acc: 0.3307\n",
      "Epoch 82/200\n",
      "2307/2307 [==============================] - 2s 915us/step - loss: 0.3694 - acc: 0.8301 - val_loss: 2.3491 - val_acc: 0.3346\n",
      "Epoch 83/200\n",
      "2307/2307 [==============================] - 2s 925us/step - loss: 0.3655 - acc: 0.8218 - val_loss: 2.3610 - val_acc: 0.3385\n",
      "Epoch 84/200\n",
      "2307/2307 [==============================] - 2s 936us/step - loss: 0.3608 - acc: 0.8305 - val_loss: 2.4167 - val_acc: 0.3346\n",
      "Epoch 85/200\n",
      "2307/2307 [==============================] - 2s 926us/step - loss: 0.3597 - acc: 0.8279 - val_loss: 2.3590 - val_acc: 0.3541\n",
      "Epoch 86/200\n",
      "2307/2307 [==============================] - 2s 928us/step - loss: 0.3675 - acc: 0.8266 - val_loss: 2.3686 - val_acc: 0.3735\n",
      "Epoch 87/200\n",
      "2307/2307 [==============================] - 2s 918us/step - loss: 0.3529 - acc: 0.8383 - val_loss: 2.3828 - val_acc: 0.3774\n",
      "Epoch 88/200\n",
      "2307/2307 [==============================] - 2s 923us/step - loss: 0.3516 - acc: 0.8366 - val_loss: 2.3893 - val_acc: 0.3813\n",
      "Epoch 89/200\n",
      "2307/2307 [==============================] - 2s 929us/step - loss: 0.3555 - acc: 0.8353 - val_loss: 2.4345 - val_acc: 0.3541\n",
      "Epoch 90/200\n",
      "2307/2307 [==============================] - 2s 938us/step - loss: 0.3440 - acc: 0.8392 - val_loss: 2.4671 - val_acc: 0.3580\n",
      "Epoch 91/200\n",
      "2307/2307 [==============================] - 2s 992us/step - loss: 0.3461 - acc: 0.8405 - val_loss: 2.4724 - val_acc: 0.3619\n",
      "Epoch 92/200\n",
      "2307/2307 [==============================] - 2s 942us/step - loss: 0.3361 - acc: 0.8405 - val_loss: 2.4314 - val_acc: 0.3580\n",
      "Epoch 93/200\n",
      "2307/2307 [==============================] - 2s 947us/step - loss: 0.3372 - acc: 0.8379 - val_loss: 2.4054 - val_acc: 0.3658\n",
      "Epoch 94/200\n",
      "2307/2307 [==============================] - 2s 965us/step - loss: 0.3427 - acc: 0.8362 - val_loss: 2.4611 - val_acc: 0.3658\n",
      "Epoch 95/200\n",
      "2307/2307 [==============================] - 2s 927us/step - loss: 0.3304 - acc: 0.8444 - val_loss: 2.4933 - val_acc: 0.3580\n",
      "Epoch 96/200\n",
      "2307/2307 [==============================] - 2s 932us/step - loss: 0.3373 - acc: 0.8440 - val_loss: 2.4123 - val_acc: 0.3619\n",
      "Epoch 97/200\n",
      "2307/2307 [==============================] - 2s 935us/step - loss: 0.3315 - acc: 0.8401 - val_loss: 2.3682 - val_acc: 0.3658\n",
      "Epoch 98/200\n",
      "2307/2307 [==============================] - 2s 915us/step - loss: 0.3108 - acc: 0.8591 - val_loss: 2.4152 - val_acc: 0.3619\n",
      "Epoch 99/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.3213 - acc: 0.8414 - val_loss: 2.4106 - val_acc: 0.3658\n",
      "Epoch 100/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.3275 - acc: 0.8409 - val_loss: 2.5279 - val_acc: 0.3696\n",
      "Epoch 101/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.3233 - acc: 0.8431 - val_loss: 2.4918 - val_acc: 0.3502\n",
      "Epoch 102/200\n",
      "2307/2307 [==============================] - 2s 987us/step - loss: 0.3181 - acc: 0.8474 - val_loss: 2.4955 - val_acc: 0.3852\n",
      "Epoch 103/200\n",
      "2307/2307 [==============================] - 2s 933us/step - loss: 0.3190 - acc: 0.8431 - val_loss: 2.5059 - val_acc: 0.3619\n",
      "Epoch 104/200\n",
      "2307/2307 [==============================] - 2s 945us/step - loss: 0.3128 - acc: 0.8522 - val_loss: 2.4858 - val_acc: 0.3774\n",
      "Epoch 105/200\n",
      "2307/2307 [==============================] - 2s 946us/step - loss: 0.3035 - acc: 0.8578 - val_loss: 2.5387 - val_acc: 0.3580\n",
      "Epoch 106/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.3227 - acc: 0.8440 - val_loss: 2.5139 - val_acc: 0.3735\n",
      "Epoch 107/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.3109 - acc: 0.8583 - val_loss: 2.4822 - val_acc: 0.3541\n",
      "Epoch 108/200\n",
      "2307/2307 [==============================] - 2s 875us/step - loss: 0.3204 - acc: 0.8444 - val_loss: 2.5095 - val_acc: 0.3463\n",
      "Epoch 109/200\n",
      "2307/2307 [==============================] - 2s 888us/step - loss: 0.3046 - acc: 0.8535 - val_loss: 2.5098 - val_acc: 0.3774\n",
      "Epoch 110/200\n",
      "2307/2307 [==============================] - 2s 904us/step - loss: 0.3156 - acc: 0.8470 - val_loss: 2.5701 - val_acc: 0.3774\n",
      "Epoch 111/200\n",
      "2307/2307 [==============================] - 2s 886us/step - loss: 0.3086 - acc: 0.8500 - val_loss: 2.5008 - val_acc: 0.3619\n",
      "Epoch 112/200\n",
      "2307/2307 [==============================] - 2s 908us/step - loss: 0.3016 - acc: 0.8570 - val_loss: 2.5628 - val_acc: 0.3891\n",
      "Epoch 113/200\n",
      "2307/2307 [==============================] - 2s 899us/step - loss: 0.2957 - acc: 0.8574 - val_loss: 2.5868 - val_acc: 0.3735\n",
      "Epoch 114/200\n",
      "2307/2307 [==============================] - 2s 979us/step - loss: 0.3051 - acc: 0.8461 - val_loss: 2.6002 - val_acc: 0.3580\n",
      "Epoch 115/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2945 - acc: 0.8578 - val_loss: 2.5740 - val_acc: 0.3852\n",
      "Epoch 116/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.3024 - acc: 0.8496 - val_loss: 2.6119 - val_acc: 0.3852\n",
      "Epoch 117/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.3054 - acc: 0.8509 - val_loss: 2.6069 - val_acc: 0.3580\n",
      "Epoch 118/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2918 - acc: 0.8570 - val_loss: 2.6065 - val_acc: 0.3463\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307/2307 [==============================] - 2s 976us/step - loss: 0.2991 - acc: 0.8505 - val_loss: 2.6284 - val_acc: 0.3541\n",
      "Epoch 120/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2994 - acc: 0.8526 - val_loss: 2.5973 - val_acc: 0.3424\n",
      "Epoch 121/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2904 - acc: 0.8539 - val_loss: 2.5609 - val_acc: 0.3502\n",
      "Epoch 122/200\n",
      "2307/2307 [==============================] - 2s 874us/step - loss: 0.2899 - acc: 0.8587 - val_loss: 2.6451 - val_acc: 0.3619\n",
      "Epoch 123/200\n",
      "2307/2307 [==============================] - 2s 873us/step - loss: 0.2911 - acc: 0.8535 - val_loss: 2.6948 - val_acc: 0.3658\n",
      "Epoch 124/200\n",
      "2307/2307 [==============================] - 2s 860us/step - loss: 0.2951 - acc: 0.8544 - val_loss: 2.6761 - val_acc: 0.3580\n",
      "Epoch 125/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2953 - acc: 0.8531 - val_loss: 2.6794 - val_acc: 0.3619\n",
      "Epoch 126/200\n",
      "2307/2307 [==============================] - 2s 992us/step - loss: 0.2910 - acc: 0.8561 - val_loss: 2.6954 - val_acc: 0.3502\n",
      "Epoch 127/200\n",
      "2307/2307 [==============================] - 2s 959us/step - loss: 0.2938 - acc: 0.8522 - val_loss: 2.7325 - val_acc: 0.3463\n",
      "Epoch 128/200\n",
      "2307/2307 [==============================] - 2s 947us/step - loss: 0.2959 - acc: 0.8570 - val_loss: 2.6985 - val_acc: 0.3580\n",
      "Epoch 129/200\n",
      "2307/2307 [==============================] - 2s 968us/step - loss: 0.2981 - acc: 0.8552 - val_loss: 2.8150 - val_acc: 0.3385\n",
      "Epoch 130/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2899 - acc: 0.8574 - val_loss: 2.8724 - val_acc: 0.3385\n",
      "Epoch 131/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2877 - acc: 0.8617 - val_loss: 2.8795 - val_acc: 0.3191\n",
      "Epoch 132/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2894 - acc: 0.8561 - val_loss: 2.8659 - val_acc: 0.3268\n",
      "Epoch 133/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2886 - acc: 0.8578 - val_loss: 2.8266 - val_acc: 0.3230\n",
      "Epoch 134/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2964 - acc: 0.8461 - val_loss: 2.7852 - val_acc: 0.3502\n",
      "Epoch 135/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2825 - acc: 0.8496 - val_loss: 2.7528 - val_acc: 0.3580\n",
      "Epoch 136/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2878 - acc: 0.8648 - val_loss: 2.7756 - val_acc: 0.3424\n",
      "Epoch 137/200\n",
      "2307/2307 [==============================] - 2s 934us/step - loss: 0.2876 - acc: 0.8604 - val_loss: 2.7690 - val_acc: 0.3463\n",
      "Epoch 138/200\n",
      "2307/2307 [==============================] - 2s 933us/step - loss: 0.2737 - acc: 0.8600 - val_loss: 2.8271 - val_acc: 0.3541\n",
      "Epoch 139/200\n",
      "2307/2307 [==============================] - 2s 904us/step - loss: 0.2864 - acc: 0.8492 - val_loss: 2.8407 - val_acc: 0.3580\n",
      "Epoch 140/200\n",
      "2307/2307 [==============================] - 2s 897us/step - loss: 0.2742 - acc: 0.8570 - val_loss: 2.8241 - val_acc: 0.3580\n",
      "Epoch 141/200\n",
      "2307/2307 [==============================] - 2s 963us/step - loss: 0.2863 - acc: 0.8565 - val_loss: 2.7558 - val_acc: 0.3580\n",
      "Epoch 142/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2816 - acc: 0.8535 - val_loss: 2.8139 - val_acc: 0.3385\n",
      "Epoch 143/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2916 - acc: 0.8552 - val_loss: 2.7768 - val_acc: 0.3541\n",
      "Epoch 144/200\n",
      "2307/2307 [==============================] - 2s 974us/step - loss: 0.2828 - acc: 0.8600 - val_loss: 2.7798 - val_acc: 0.3541\n",
      "Epoch 145/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2765 - acc: 0.8613 - val_loss: 2.8085 - val_acc: 0.3502\n",
      "Epoch 146/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2831 - acc: 0.8591 - val_loss: 2.8308 - val_acc: 0.3502\n",
      "Epoch 147/200\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 0.2743 - acc: 0.8578 - val_loss: 2.7587 - val_acc: 0.3463\n",
      "Epoch 148/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2692 - acc: 0.8669 - val_loss: 2.7845 - val_acc: 0.3541\n",
      "Epoch 149/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2732 - acc: 0.8587 - val_loss: 2.8682 - val_acc: 0.3346\n",
      "Epoch 150/200\n",
      "2307/2307 [==============================] - 2s 931us/step - loss: 0.2727 - acc: 0.8613 - val_loss: 2.8957 - val_acc: 0.3385\n",
      "Epoch 151/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2819 - acc: 0.8561 - val_loss: 3.0202 - val_acc: 0.3035\n",
      "Epoch 152/200\n",
      "2307/2307 [==============================] - 2s 1ms/step - loss: 0.2760 - acc: 0.8596 - val_loss: 2.9151 - val_acc: 0.3424\n",
      "Epoch 153/200\n",
      "2307/2307 [==============================] - 2s 957us/step - loss: 0.2771 - acc: 0.8600 - val_loss: 2.9232 - val_acc: 0.3424\n",
      "Epoch 154/200\n",
      "2307/2307 [==============================] - 2s 924us/step - loss: 0.2766 - acc: 0.8578 - val_loss: 2.8584 - val_acc: 0.3541\n",
      "Epoch 155/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.2765 - acc: 0.8604 - val_loss: 2.8313 - val_acc: 0.3268\n",
      "Epoch 156/200\n",
      "2307/2307 [==============================] - 2s 919us/step - loss: 0.2743 - acc: 0.8613 - val_loss: 2.8765 - val_acc: 0.3658\n",
      "Epoch 157/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.2787 - acc: 0.8570 - val_loss: 2.9286 - val_acc: 0.3463\n",
      "Epoch 158/200\n",
      "2307/2307 [==============================] - 2s 914us/step - loss: 0.2752 - acc: 0.8656 - val_loss: 2.9548 - val_acc: 0.3307\n",
      "Epoch 159/200\n",
      "2307/2307 [==============================] - 2s 912us/step - loss: 0.2665 - acc: 0.8626 - val_loss: 2.9892 - val_acc: 0.3035\n",
      "Epoch 160/200\n",
      "2307/2307 [==============================] - 2s 929us/step - loss: 0.2690 - acc: 0.8661 - val_loss: 2.9437 - val_acc: 0.3113\n",
      "Epoch 161/200\n",
      "2307/2307 [==============================] - 2s 913us/step - loss: 0.2638 - acc: 0.8691 - val_loss: 2.9598 - val_acc: 0.3268\n",
      "Epoch 162/200\n",
      "2307/2307 [==============================] - 2s 937us/step - loss: 0.2772 - acc: 0.8604 - val_loss: 2.9840 - val_acc: 0.3424\n",
      "Epoch 163/200\n",
      "2307/2307 [==============================] - 2s 905us/step - loss: 0.2716 - acc: 0.8695 - val_loss: 2.9712 - val_acc: 0.3346\n",
      "Epoch 164/200\n",
      "2307/2307 [==============================] - 2s 945us/step - loss: 0.2789 - acc: 0.8548 - val_loss: 2.9863 - val_acc: 0.3385\n",
      "Epoch 165/200\n",
      "2307/2307 [==============================] - 2s 937us/step - loss: 0.2702 - acc: 0.8596 - val_loss: 2.9896 - val_acc: 0.3230\n",
      "Epoch 166/200\n",
      "2307/2307 [==============================] - 2s 930us/step - loss: 0.2743 - acc: 0.8643 - val_loss: 2.9373 - val_acc: 0.3307\n",
      "Epoch 167/200\n",
      "2307/2307 [==============================] - 2s 917us/step - loss: 0.2686 - acc: 0.8635 - val_loss: 2.9234 - val_acc: 0.3463\n",
      "Epoch 168/200\n",
      "2307/2307 [==============================] - 2s 931us/step - loss: 0.2844 - acc: 0.8509 - val_loss: 3.0023 - val_acc: 0.3385\n",
      "Epoch 169/200\n",
      "2307/2307 [==============================] - 2s 918us/step - loss: 0.2804 - acc: 0.8565 - val_loss: 2.9439 - val_acc: 0.3346\n",
      "Epoch 170/200\n",
      "2307/2307 [==============================] - 2s 952us/step - loss: 0.2744 - acc: 0.8613 - val_loss: 2.8537 - val_acc: 0.3658\n",
      "Epoch 171/200\n",
      "2307/2307 [==============================] - 2s 918us/step - loss: 0.2750 - acc: 0.8531 - val_loss: 2.9020 - val_acc: 0.3502\n",
      "Epoch 172/200\n",
      "2307/2307 [==============================] - 2s 926us/step - loss: 0.2723 - acc: 0.8596 - val_loss: 2.9341 - val_acc: 0.3385\n",
      "Epoch 173/200\n",
      "2307/2307 [==============================] - 2s 926us/step - loss: 0.2739 - acc: 0.8682 - val_loss: 2.9184 - val_acc: 0.3696\n",
      "Epoch 174/200\n",
      "2307/2307 [==============================] - 2s 941us/step - loss: 0.2673 - acc: 0.8669 - val_loss: 2.9498 - val_acc: 0.3385\n",
      "Epoch 175/200\n",
      "2307/2307 [==============================] - 2s 932us/step - loss: 0.2770 - acc: 0.8591 - val_loss: 3.0421 - val_acc: 0.3268\n",
      "Epoch 176/200\n",
      "2307/2307 [==============================] - 2s 932us/step - loss: 0.2722 - acc: 0.8665 - val_loss: 3.0186 - val_acc: 0.3735\n",
      "Epoch 177/200\n",
      "2307/2307 [==============================] - 2s 935us/step - loss: 0.2847 - acc: 0.8570 - val_loss: 2.9571 - val_acc: 0.3385\n",
      "Epoch 178/200\n",
      "2307/2307 [==============================] - 2s 877us/step - loss: 0.2695 - acc: 0.8613 - val_loss: 2.9844 - val_acc: 0.3346\n",
      "Epoch 179/200\n",
      "2307/2307 [==============================] - 2s 872us/step - loss: 0.2681 - acc: 0.8613 - val_loss: 2.9767 - val_acc: 0.3502\n",
      "Epoch 180/200\n",
      "2307/2307 [==============================] - 2s 875us/step - loss: 0.2759 - acc: 0.8591 - val_loss: 2.9843 - val_acc: 0.3191\n",
      "Epoch 181/200\n",
      "2307/2307 [==============================] - 2s 856us/step - loss: 0.2681 - acc: 0.8604 - val_loss: 2.9884 - val_acc: 0.3424\n",
      "Epoch 182/200\n",
      "2307/2307 [==============================] - 2s 882us/step - loss: 0.2664 - acc: 0.8609 - val_loss: 2.9485 - val_acc: 0.3424\n",
      "Epoch 183/200\n",
      "2307/2307 [==============================] - 2s 910us/step - loss: 0.2718 - acc: 0.8531 - val_loss: 2.9289 - val_acc: 0.3502\n",
      "Epoch 184/200\n",
      "2307/2307 [==============================] - 2s 866us/step - loss: 0.2704 - acc: 0.8591 - val_loss: 2.9447 - val_acc: 0.3346\n",
      "Epoch 185/200\n",
      "2307/2307 [==============================] - 2s 881us/step - loss: 0.2651 - acc: 0.8669 - val_loss: 2.9767 - val_acc: 0.3307\n",
      "Epoch 186/200\n",
      "2307/2307 [==============================] - 2s 876us/step - loss: 0.2724 - acc: 0.8591 - val_loss: 2.9603 - val_acc: 0.3307\n",
      "Epoch 187/200\n",
      "2307/2307 [==============================] - 2s 884us/step - loss: 0.2631 - acc: 0.8661 - val_loss: 2.9559 - val_acc: 0.3307\n",
      "Epoch 188/200\n",
      "2307/2307 [==============================] - 2s 869us/step - loss: 0.2771 - acc: 0.8518 - val_loss: 2.9499 - val_acc: 0.3230\n",
      "Epoch 189/200\n",
      "2307/2307 [==============================] - 2s 886us/step - loss: 0.2641 - acc: 0.8674 - val_loss: 3.0126 - val_acc: 0.3346\n",
      "Epoch 190/200\n",
      "2307/2307 [==============================] - 2s 891us/step - loss: 0.2722 - acc: 0.8652 - val_loss: 2.9862 - val_acc: 0.3230\n",
      "Epoch 191/200\n",
      "2307/2307 [==============================] - 2s 891us/step - loss: 0.2690 - acc: 0.8626 - val_loss: 3.0047 - val_acc: 0.3385\n",
      "Epoch 192/200\n",
      "2307/2307 [==============================] - 2s 888us/step - loss: 0.2622 - acc: 0.8648 - val_loss: 3.0007 - val_acc: 0.3463\n",
      "Epoch 193/200\n",
      "2307/2307 [==============================] - 2s 884us/step - loss: 0.2687 - acc: 0.8687 - val_loss: 2.9892 - val_acc: 0.3424\n",
      "Epoch 194/200\n",
      "2307/2307 [==============================] - 2s 896us/step - loss: 0.2786 - acc: 0.8604 - val_loss: 2.9668 - val_acc: 0.3385\n",
      "Epoch 195/200\n",
      "2307/2307 [==============================] - 2s 882us/step - loss: 0.2595 - acc: 0.8665 - val_loss: 3.0211 - val_acc: 0.3385\n",
      "Epoch 196/200\n",
      "2307/2307 [==============================] - 2s 876us/step - loss: 0.2692 - acc: 0.8617 - val_loss: 2.9958 - val_acc: 0.3502\n",
      "Epoch 197/200\n",
      "2307/2307 [==============================] - 2s 896us/step - loss: 0.2728 - acc: 0.8661 - val_loss: 3.0531 - val_acc: 0.3541\n",
      "Epoch 198/200\n",
      "2307/2307 [==============================] - 2s 952us/step - loss: 0.2647 - acc: 0.8695 - val_loss: 2.9814 - val_acc: 0.3385\n",
      "Epoch 199/200\n",
      "2307/2307 [==============================] - 2s 956us/step - loss: 0.2734 - acc: 0.8617 - val_loss: 2.9769 - val_acc: 0.3502\n",
      "Epoch 200/200\n",
      "2307/2307 [==============================] - 2s 899us/step - loss: 0.2696 - acc: 0.8661 - val_loss: 2.9696 - val_acc: 0.3307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4e2a2208>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, validation_split=0.1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.16\n",
      "acc: 0.34\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = 32)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_from</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>encoded_sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_30</th>\n",
       "      <th>pc_31</th>\n",
       "      <th>pc_32</th>\n",
       "      <th>pc_33</th>\n",
       "      <th>pc_34</th>\n",
       "      <th>pc_35</th>\n",
       "      <th>pc_36</th>\n",
       "      <th>pc_37</th>\n",
       "      <th>pc_38</th>\n",
       "      <th>signal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>assuming acceleration of to but in a comfortab...</td>\n",
       "      <td>-0.031750</td>\n",
       "      <td>-0.028850</td>\n",
       "      <td>-0.030290</td>\n",
       "      <td>-0.018736</td>\n",
       "      <td>-0.060675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.045822</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.100572</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>0.035932</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>is capable of transporting satellite to orbit ...</td>\n",
       "      <td>-0.059331</td>\n",
       "      <td>-0.099826</td>\n",
       "      <td>-0.154772</td>\n",
       "      <td>-0.040355</td>\n",
       "      <td>0.072285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>-0.019813</td>\n",
       "      <td>-0.035809</td>\n",
       "      <td>-0.034079</td>\n",
       "      <td>-0.014687</td>\n",
       "      <td>-0.008986</td>\n",
       "      <td>-0.019845</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yup</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>0.069531</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>-0.037774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>0.065735</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>-0.021751</td>\n",
       "      <td>-0.014138</td>\n",
       "      <td>-0.037047</td>\n",
       "      <td>-0.050031</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>part</td>\n",
       "      <td>-0.005050</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.016279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009052</td>\n",
       "      <td>-0.008601</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.007619</td>\n",
       "      <td>-0.005289</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>-0.011967</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>fly to most place on earth in under min and an...</td>\n",
       "      <td>-0.031167</td>\n",
       "      <td>-0.027725</td>\n",
       "      <td>-0.012331</td>\n",
       "      <td>-0.039909</td>\n",
       "      <td>-0.070462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>-0.039462</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>-0.012277</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>0.040576</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>-0.031236</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   retweet_from  tweet_length  encoded_sentiment  polarity  \\\n",
       "0           171           105                  1  0.366667   \n",
       "1            77           113                  1  0.200000   \n",
       "2           171             6                  0  0.000000   \n",
       "3           171             7                  0  0.000000   \n",
       "4           171            96                  1  0.650000   \n",
       "\n",
       "                                               tweet      pc_1      pc_2  \\\n",
       "0  assuming acceleration of to but in a comfortab... -0.031750 -0.028850   \n",
       "1  is capable of transporting satellite to orbit ... -0.059331 -0.099826   \n",
       "2                                                yup -0.002330  0.033983   \n",
       "3                                               part -0.005050  0.024117   \n",
       "4  fly to most place on earth in under min and an... -0.031167 -0.027725   \n",
       "\n",
       "       pc_3      pc_4      pc_5    ...        pc_30     pc_31     pc_32  \\\n",
       "0 -0.030290 -0.018736 -0.060675    ...     0.017885  0.045822 -0.006862   \n",
       "1 -0.154772 -0.040355  0.072285    ...    -0.011667  0.003882  0.018002   \n",
       "2  0.069531 -0.014177 -0.037774    ...     0.015722 -0.025726  0.065735   \n",
       "3  0.043362 -0.001804 -0.016279    ...    -0.009052 -0.008601  0.001285   \n",
       "4 -0.012331 -0.039909 -0.070462    ...     0.020042  0.030526 -0.039462   \n",
       "\n",
       "      pc_33     pc_34     pc_35     pc_36     pc_37     pc_38  signal_y  \n",
       "0 -0.012954 -0.005468 -0.100572 -0.029374  0.041363  0.035932      stay  \n",
       "1 -0.019813 -0.035809 -0.034079 -0.014687 -0.008986 -0.019845      stay  \n",
       "2  0.041686 -0.021751 -0.014138 -0.037047 -0.050031 -0.084722      stay  \n",
       "3 -0.007619 -0.005289 -0.025700 -0.008989 -0.011967 -0.004665      stay  \n",
       "4  0.088186 -0.012277  0.033849  0.040576  0.051975 -0.031236      stay  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = test.drop(columns=['signal_y', 'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2564, 42) (2564, 3)\n",
      "(641, 42) (641, 3)\n"
     ]
    }
   ],
   "source": [
    "# y = pd.get_dummies(test['signal_y']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 20)                860       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,633\n",
      "Trainable params: 1,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(20, input_dim=42, kernel_initializer='normal', activation='tanh'))\n",
    "model2.add(Dense(20, kernel_initializer='normal', activation='tanh'))\n",
    "model2.add(Dropout(0.01))\n",
    "model2.add(Dense(20, kernel_initializer='normal', activation='tanh'))\n",
    "model2.add(Dropout(0.01))\n",
    "model2.add(Dense(20, kernel_initializer='normal', activation='tanh'))\n",
    "model2.add(Dropout(0.01))\n",
    "model2.add(Dense(20, kernel_initializer='normal', activation='tanh'))\n",
    "model2.add(Dense(10, activation='tanh'))\n",
    "model2.add(Dense(10, activation='tanh'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2307 samples, validate on 257 samples\n",
      "Epoch 1/120\n",
      "2307/2307 [==============================] - 1s 369us/step - loss: 1.0900 - acc: 0.4027 - val_loss: 1.0929 - val_acc: 0.3930\n",
      "Epoch 2/120\n",
      "2307/2307 [==============================] - 0s 70us/step - loss: 1.0871 - acc: 0.4083 - val_loss: 1.0885 - val_acc: 0.4047\n",
      "Epoch 3/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0855 - acc: 0.4101 - val_loss: 1.0864 - val_acc: 0.4047\n",
      "Epoch 4/120\n",
      "2307/2307 [==============================] - 0s 95us/step - loss: 1.0856 - acc: 0.4105 - val_loss: 1.0883 - val_acc: 0.4047\n",
      "Epoch 5/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0845 - acc: 0.4105 - val_loss: 1.0889 - val_acc: 0.4047\n",
      "Epoch 6/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0849 - acc: 0.4109 - val_loss: 1.0887 - val_acc: 0.4008\n",
      "Epoch 7/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0844 - acc: 0.4105 - val_loss: 1.0894 - val_acc: 0.4008\n",
      "Epoch 8/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0849 - acc: 0.4092 - val_loss: 1.0893 - val_acc: 0.4047\n",
      "Epoch 9/120\n",
      "2307/2307 [==============================] - 0s 75us/step - loss: 1.0849 - acc: 0.4075 - val_loss: 1.0874 - val_acc: 0.4047\n",
      "Epoch 10/120\n",
      "2307/2307 [==============================] - 0s 72us/step - loss: 1.0847 - acc: 0.4014 - val_loss: 1.0899 - val_acc: 0.4047\n",
      "Epoch 11/120\n",
      "2307/2307 [==============================] - 0s 74us/step - loss: 1.0857 - acc: 0.4118 - val_loss: 1.0868 - val_acc: 0.4008\n",
      "Epoch 12/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0836 - acc: 0.4118 - val_loss: 1.0876 - val_acc: 0.4008\n",
      "Epoch 13/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0834 - acc: 0.4127 - val_loss: 1.0865 - val_acc: 0.4047\n",
      "Epoch 14/120\n",
      "2307/2307 [==============================] - 0s 74us/step - loss: 1.0840 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 15/120\n",
      "2307/2307 [==============================] - 0s 73us/step - loss: 1.0838 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4008\n",
      "Epoch 16/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0847 - acc: 0.4127 - val_loss: 1.0899 - val_acc: 0.4047\n",
      "Epoch 17/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0843 - acc: 0.4131 - val_loss: 1.0881 - val_acc: 0.4008\n",
      "Epoch 18/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0843 - acc: 0.4101 - val_loss: 1.0863 - val_acc: 0.4047\n",
      "Epoch 19/120\n",
      "2307/2307 [==============================] - 0s 104us/step - loss: 1.0831 - acc: 0.4092 - val_loss: 1.0899 - val_acc: 0.4008\n",
      "Epoch 20/120\n",
      "2307/2307 [==============================] - 0s 96us/step - loss: 1.0849 - acc: 0.4118 - val_loss: 1.0864 - val_acc: 0.4008\n",
      "Epoch 21/120\n",
      "2307/2307 [==============================] - 0s 98us/step - loss: 1.0839 - acc: 0.4114 - val_loss: 1.0862 - val_acc: 0.4047\n",
      "Epoch 22/120\n",
      "2307/2307 [==============================] - 0s 102us/step - loss: 1.0851 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 23/120\n",
      "2307/2307 [==============================] - 0s 98us/step - loss: 1.0835 - acc: 0.4114 - val_loss: 1.0866 - val_acc: 0.3891\n",
      "Epoch 24/120\n",
      "2307/2307 [==============================] - 0s 92us/step - loss: 1.0838 - acc: 0.4140 - val_loss: 1.0872 - val_acc: 0.4047\n",
      "Epoch 25/120\n",
      "2307/2307 [==============================] - 0s 91us/step - loss: 1.0849 - acc: 0.4131 - val_loss: 1.0855 - val_acc: 0.4008\n",
      "Epoch 26/120\n",
      "2307/2307 [==============================] - 0s 102us/step - loss: 1.0833 - acc: 0.4114 - val_loss: 1.0892 - val_acc: 0.4008\n",
      "Epoch 27/120\n",
      "2307/2307 [==============================] - 0s 98us/step - loss: 1.0824 - acc: 0.4148 - val_loss: 1.0860 - val_acc: 0.4008\n",
      "Epoch 28/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0830 - acc: 0.4096 - val_loss: 1.0871 - val_acc: 0.4047\n",
      "Epoch 29/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0838 - acc: 0.4109 - val_loss: 1.0877 - val_acc: 0.4047\n",
      "Epoch 30/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0842 - acc: 0.4144 - val_loss: 1.0862 - val_acc: 0.4047\n",
      "Epoch 31/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0834 - acc: 0.4105 - val_loss: 1.0874 - val_acc: 0.3891\n",
      "Epoch 32/120\n",
      "2307/2307 [==============================] - 0s 72us/step - loss: 1.0820 - acc: 0.4135 - val_loss: 1.0917 - val_acc: 0.4047\n",
      "Epoch 33/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0841 - acc: 0.4088 - val_loss: 1.0857 - val_acc: 0.4086\n",
      "Epoch 34/120\n",
      "2307/2307 [==============================] - 0s 77us/step - loss: 1.0832 - acc: 0.4109 - val_loss: 1.0877 - val_acc: 0.4047\n",
      "Epoch 35/120\n",
      "2307/2307 [==============================] - 0s 77us/step - loss: 1.0833 - acc: 0.4131 - val_loss: 1.0856 - val_acc: 0.4047\n",
      "Epoch 36/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0822 - acc: 0.4118 - val_loss: 1.0901 - val_acc: 0.4008\n",
      "Epoch 37/120\n",
      "2307/2307 [==============================] - 0s 90us/step - loss: 1.0831 - acc: 0.4153 - val_loss: 1.0880 - val_acc: 0.3891\n",
      "Epoch 38/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0825 - acc: 0.4131 - val_loss: 1.0859 - val_acc: 0.4047\n",
      "Epoch 39/120\n",
      "2307/2307 [==============================] - 0s 74us/step - loss: 1.0833 - acc: 0.4118 - val_loss: 1.0861 - val_acc: 0.4008\n",
      "Epoch 40/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0840 - acc: 0.4127 - val_loss: 1.0912 - val_acc: 0.4008\n",
      "Epoch 41/120\n",
      "2307/2307 [==============================] - 0s 71us/step - loss: 1.0834 - acc: 0.4096 - val_loss: 1.0854 - val_acc: 0.4008\n",
      "Epoch 42/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0836 - acc: 0.4127 - val_loss: 1.0870 - val_acc: 0.4008\n",
      "Epoch 43/120\n",
      "2307/2307 [==============================] - 0s 77us/step - loss: 1.0839 - acc: 0.4122 - val_loss: 1.0866 - val_acc: 0.4047\n",
      "Epoch 44/120\n",
      "2307/2307 [==============================] - 0s 71us/step - loss: 1.0826 - acc: 0.4122 - val_loss: 1.0896 - val_acc: 0.4047\n",
      "Epoch 45/120\n",
      "2307/2307 [==============================] - 0s 76us/step - loss: 1.0826 - acc: 0.4118 - val_loss: 1.0865 - val_acc: 0.4008\n",
      "Epoch 46/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0815 - acc: 0.4140 - val_loss: 1.0909 - val_acc: 0.3930\n",
      "Epoch 47/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0817 - acc: 0.4140 - val_loss: 1.0913 - val_acc: 0.4008\n",
      "Epoch 48/120\n",
      "2307/2307 [==============================] - 0s 90us/step - loss: 1.0823 - acc: 0.4114 - val_loss: 1.0895 - val_acc: 0.4047\n",
      "Epoch 49/120\n",
      "2307/2307 [==============================] - 0s 81us/step - loss: 1.0823 - acc: 0.4114 - val_loss: 1.0870 - val_acc: 0.4008\n",
      "Epoch 50/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0815 - acc: 0.4148 - val_loss: 1.0891 - val_acc: 0.4047\n",
      "Epoch 51/120\n",
      "2307/2307 [==============================] - 0s 86us/step - loss: 1.0825 - acc: 0.4161 - val_loss: 1.0841 - val_acc: 0.4047\n",
      "Epoch 52/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0805 - acc: 0.4144 - val_loss: 1.0904 - val_acc: 0.3930\n",
      "Epoch 53/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0816 - acc: 0.4148 - val_loss: 1.0864 - val_acc: 0.4008\n",
      "Epoch 54/120\n",
      "2307/2307 [==============================] - 0s 75us/step - loss: 1.0815 - acc: 0.4148 - val_loss: 1.0882 - val_acc: 0.4008\n",
      "Epoch 55/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0809 - acc: 0.4144 - val_loss: 1.0878 - val_acc: 0.4008\n",
      "Epoch 56/120\n",
      "2307/2307 [==============================] - 0s 87us/step - loss: 1.0812 - acc: 0.4179 - val_loss: 1.1022 - val_acc: 0.3735\n",
      "Epoch 57/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0830 - acc: 0.4101 - val_loss: 1.0875 - val_acc: 0.4086\n",
      "Epoch 58/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0816 - acc: 0.4144 - val_loss: 1.0930 - val_acc: 0.3891\n",
      "Epoch 59/120\n",
      "2307/2307 [==============================] - 0s 81us/step - loss: 1.0809 - acc: 0.4161 - val_loss: 1.0993 - val_acc: 0.4047\n",
      "Epoch 60/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0822 - acc: 0.4140 - val_loss: 1.0904 - val_acc: 0.4047\n",
      "Epoch 61/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0801 - acc: 0.4122 - val_loss: 1.0878 - val_acc: 0.4047\n",
      "Epoch 62/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0808 - acc: 0.4153 - val_loss: 1.0890 - val_acc: 0.3930\n",
      "Epoch 63/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0795 - acc: 0.4144 - val_loss: 1.0882 - val_acc: 0.4008\n",
      "Epoch 64/120\n",
      "2307/2307 [==============================] - 0s 88us/step - loss: 1.0816 - acc: 0.4144 - val_loss: 1.0860 - val_acc: 0.4047\n",
      "Epoch 65/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0803 - acc: 0.4131 - val_loss: 1.0902 - val_acc: 0.3969\n",
      "Epoch 66/120\n",
      "2307/2307 [==============================] - 0s 89us/step - loss: 1.0800 - acc: 0.4161 - val_loss: 1.0904 - val_acc: 0.4008\n",
      "Epoch 67/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0796 - acc: 0.4144 - val_loss: 1.0893 - val_acc: 0.4008\n",
      "Epoch 68/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0811 - acc: 0.4140 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 69/120\n",
      "2307/2307 [==============================] - 0s 83us/step - loss: 1.0805 - acc: 0.4170 - val_loss: 1.0868 - val_acc: 0.4008\n",
      "Epoch 70/120\n",
      "2307/2307 [==============================] - 0s 88us/step - loss: 1.0791 - acc: 0.4179 - val_loss: 1.0915 - val_acc: 0.4008\n",
      "Epoch 71/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0787 - acc: 0.4161 - val_loss: 1.0892 - val_acc: 0.4008\n",
      "Epoch 72/120\n",
      "2307/2307 [==============================] - 0s 75us/step - loss: 1.0791 - acc: 0.4161 - val_loss: 1.0912 - val_acc: 0.3930\n",
      "Epoch 73/120\n",
      "2307/2307 [==============================] - 0s 72us/step - loss: 1.0791 - acc: 0.4157 - val_loss: 1.0863 - val_acc: 0.4008\n",
      "Epoch 74/120\n",
      "2307/2307 [==============================] - 0s 74us/step - loss: 1.0797 - acc: 0.4153 - val_loss: 1.0879 - val_acc: 0.4047\n",
      "Epoch 75/120\n",
      "2307/2307 [==============================] - 0s 87us/step - loss: 1.0778 - acc: 0.4170 - val_loss: 1.0988 - val_acc: 0.4008\n",
      "Epoch 76/120\n",
      "2307/2307 [==============================] - 0s 76us/step - loss: 1.0789 - acc: 0.4179 - val_loss: 1.0936 - val_acc: 0.3930\n",
      "Epoch 77/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0763 - acc: 0.4205 - val_loss: 1.0911 - val_acc: 0.3969\n",
      "Epoch 78/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0769 - acc: 0.4209 - val_loss: 1.0898 - val_acc: 0.3969\n",
      "Epoch 79/120\n",
      "2307/2307 [==============================] - 0s 93us/step - loss: 1.0762 - acc: 0.4192 - val_loss: 1.0952 - val_acc: 0.3969\n",
      "Epoch 80/120\n",
      "2307/2307 [==============================] - 0s 105us/step - loss: 1.0777 - acc: 0.4196 - val_loss: 1.0907 - val_acc: 0.4047\n",
      "Epoch 81/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0770 - acc: 0.4205 - val_loss: 1.0922 - val_acc: 0.4008\n",
      "Epoch 82/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0754 - acc: 0.4187 - val_loss: 1.0965 - val_acc: 0.4008\n",
      "Epoch 83/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0744 - acc: 0.4218 - val_loss: 1.0946 - val_acc: 0.4047\n",
      "Epoch 84/120\n",
      "2307/2307 [==============================] - 0s 90us/step - loss: 1.0749 - acc: 0.4205 - val_loss: 1.0902 - val_acc: 0.4008\n",
      "Epoch 85/120\n",
      "2307/2307 [==============================] - 0s 81us/step - loss: 1.0722 - acc: 0.4248 - val_loss: 1.1045 - val_acc: 0.3891\n",
      "Epoch 86/120\n",
      "2307/2307 [==============================] - 0s 83us/step - loss: 1.0737 - acc: 0.4213 - val_loss: 1.0869 - val_acc: 0.4047\n",
      "Epoch 87/120\n",
      "2307/2307 [==============================] - 0s 90us/step - loss: 1.0721 - acc: 0.4231 - val_loss: 1.0862 - val_acc: 0.4008\n",
      "Epoch 88/120\n",
      "2307/2307 [==============================] - 0s 96us/step - loss: 1.0702 - acc: 0.4235 - val_loss: 1.0911 - val_acc: 0.4047\n",
      "Epoch 89/120\n",
      "2307/2307 [==============================] - 0s 81us/step - loss: 1.0727 - acc: 0.4174 - val_loss: 1.1088 - val_acc: 0.3930\n",
      "Epoch 90/120\n",
      "2307/2307 [==============================] - 0s 87us/step - loss: 1.0714 - acc: 0.4235 - val_loss: 1.0953 - val_acc: 0.4008\n",
      "Epoch 91/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0749 - acc: 0.4213 - val_loss: 1.0975 - val_acc: 0.4008\n",
      "Epoch 92/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0722 - acc: 0.4226 - val_loss: 1.0945 - val_acc: 0.3969\n",
      "Epoch 93/120\n",
      "2307/2307 [==============================] - 0s 80us/step - loss: 1.0716 - acc: 0.4213 - val_loss: 1.0954 - val_acc: 0.4047\n",
      "Epoch 94/120\n",
      "2307/2307 [==============================] - 0s 81us/step - loss: 1.0714 - acc: 0.4257 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 95/120\n",
      "2307/2307 [==============================] - 0s 102us/step - loss: 1.0744 - acc: 0.4205 - val_loss: 1.0971 - val_acc: 0.4047\n",
      "Epoch 96/120\n",
      "2307/2307 [==============================] - 0s 90us/step - loss: 1.0711 - acc: 0.4239 - val_loss: 1.0930 - val_acc: 0.3969\n",
      "Epoch 97/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0693 - acc: 0.4213 - val_loss: 1.0936 - val_acc: 0.4008\n",
      "Epoch 98/120\n",
      "2307/2307 [==============================] - 0s 83us/step - loss: 1.0679 - acc: 0.4205 - val_loss: 1.1125 - val_acc: 0.3891\n",
      "Epoch 99/120\n",
      "2307/2307 [==============================] - 0s 82us/step - loss: 1.0723 - acc: 0.4218 - val_loss: 1.1028 - val_acc: 0.3969\n",
      "Epoch 100/120\n",
      "2307/2307 [==============================] - 0s 84us/step - loss: 1.0723 - acc: 0.4196 - val_loss: 1.0958 - val_acc: 0.4008\n",
      "Epoch 101/120\n",
      "2307/2307 [==============================] - 0s 76us/step - loss: 1.0696 - acc: 0.4226 - val_loss: 1.0953 - val_acc: 0.4008\n",
      "Epoch 102/120\n",
      "2307/2307 [==============================] - 0s 78us/step - loss: 1.0695 - acc: 0.4222 - val_loss: 1.0972 - val_acc: 0.4008\n",
      "Epoch 103/120\n",
      "2307/2307 [==============================] - 0s 86us/step - loss: 1.0678 - acc: 0.4261 - val_loss: 1.0979 - val_acc: 0.4008\n",
      "Epoch 104/120\n",
      "2307/2307 [==============================] - 0s 87us/step - loss: 1.0671 - acc: 0.4235 - val_loss: 1.1022 - val_acc: 0.3969\n",
      "Epoch 105/120\n",
      "2307/2307 [==============================] - 0s 83us/step - loss: 1.0697 - acc: 0.4235 - val_loss: 1.1033 - val_acc: 0.4047\n",
      "Epoch 106/120\n",
      "2307/2307 [==============================] - 0s 83us/step - loss: 1.0674 - acc: 0.4248 - val_loss: 1.0946 - val_acc: 0.3930\n",
      "Epoch 107/120\n",
      "2307/2307 [==============================] - 0s 87us/step - loss: 1.0699 - acc: 0.4222 - val_loss: 1.0960 - val_acc: 0.4047\n",
      "Epoch 108/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0654 - acc: 0.4235 - val_loss: 1.0907 - val_acc: 0.3969\n",
      "Epoch 109/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0697 - acc: 0.4244 - val_loss: 1.1275 - val_acc: 0.4008\n",
      "Epoch 110/120\n",
      "2307/2307 [==============================] - 0s 85us/step - loss: 1.0668 - acc: 0.4244 - val_loss: 1.0967 - val_acc: 0.3969\n",
      "Epoch 111/120\n",
      "2307/2307 [==============================] - 0s 77us/step - loss: 1.0634 - acc: 0.4265 - val_loss: 1.0946 - val_acc: 0.3891\n",
      "Epoch 112/120\n",
      "2307/2307 [==============================] - 0s 76us/step - loss: 1.0648 - acc: 0.4235 - val_loss: 1.1054 - val_acc: 0.4008\n",
      "Epoch 113/120\n",
      "2307/2307 [==============================] - 0s 71us/step - loss: 1.0647 - acc: 0.4270 - val_loss: 1.0989 - val_acc: 0.3774\n",
      "Epoch 114/120\n",
      "2307/2307 [==============================] - 0s 73us/step - loss: 1.0675 - acc: 0.4192 - val_loss: 1.1065 - val_acc: 0.3969\n",
      "Epoch 115/120\n",
      "2307/2307 [==============================] - 0s 105us/step - loss: 1.0642 - acc: 0.4261 - val_loss: 1.0916 - val_acc: 0.3969\n",
      "Epoch 116/120\n",
      "2307/2307 [==============================] - 0s 91us/step - loss: 1.0644 - acc: 0.4252 - val_loss: 1.0993 - val_acc: 0.4047\n",
      "Epoch 117/120\n",
      "2307/2307 [==============================] - 0s 71us/step - loss: 1.0625 - acc: 0.4248 - val_loss: 1.1022 - val_acc: 0.3813\n",
      "Epoch 118/120\n",
      "2307/2307 [==============================] - 0s 74us/step - loss: 1.0573 - acc: 0.4352 - val_loss: 1.1531 - val_acc: 0.3969\n",
      "Epoch 119/120\n",
      "2307/2307 [==============================] - 0s 79us/step - loss: 1.0681 - acc: 0.4304 - val_loss: 1.0978 - val_acc: 0.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "2307/2307 [==============================] - 0s 65us/step - loss: 1.0618 - acc: 0.4283 - val_loss: 1.0996 - val_acc: 0.4008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3a07bac8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=120, validation_split=.1, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(42, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(21, activation = 'relu'))\n",
    "classifier.add(Dense(21, activation = 'relu'))\n",
    "classifier.add(Dense(10, kernel_regularizer=regularizers.l2(0.05), activation='relu'))\n",
    "# classifier.add(Dense(10, kernel_regularizer=regularizers.l2(0.05), activation='relu'))\n",
    "# classifier.add(Dense(5, kernel_regularizer=regularizers.l2(0.05), activation='relu'))\n",
    "# classifier.add(Dense(5, activation = 'tanh'))\n",
    "classifier.add(Dense(2, activation = 'softmax'))\n",
    "adam = optimizers.Adam(lr=.01, decay=0.0005)\n",
    "\n",
    "classifier.compile(optimizer = adam, loss = 'binary_crossentropy', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2307 samples, validate on 257 samples\n",
      "Epoch 1/50\n",
      "2307/2307 [==============================] - 3s 1ms/step - loss: 1.2233 - acc: 0.3975 - val_loss: 1.1033 - val_acc: 0.4047\n",
      "Epoch 2/50\n",
      "2307/2307 [==============================] - 0s 134us/step - loss: 1.0918 - acc: 0.4114 - val_loss: 1.0889 - val_acc: 0.4047\n",
      "Epoch 3/50\n",
      "2307/2307 [==============================] - 0s 134us/step - loss: 1.0857 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 4/50\n",
      "2307/2307 [==============================] - 0s 140us/step - loss: 1.0848 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 5/50\n",
      "2307/2307 [==============================] - 0s 132us/step - loss: 1.0849 - acc: 0.4114 - val_loss: 1.0849 - val_acc: 0.4047\n",
      "Epoch 6/50\n",
      "2307/2307 [==============================] - 0s 135us/step - loss: 1.0849 - acc: 0.4114 - val_loss: 1.0849 - val_acc: 0.4047\n",
      "Epoch 7/50\n",
      "2307/2307 [==============================] - 0s 135us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0859 - val_acc: 0.4047\n",
      "Epoch 8/50\n",
      "2307/2307 [==============================] - 0s 133us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 9/50\n",
      "2307/2307 [==============================] - 0s 133us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 10/50\n",
      "2307/2307 [==============================] - 0s 129us/step - loss: 1.0846 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 11/50\n",
      "2307/2307 [==============================] - 0s 135us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 12/50\n",
      "2307/2307 [==============================] - 0s 145us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 13/50\n",
      "2307/2307 [==============================] - 0s 150us/step - loss: 1.0849 - acc: 0.4114 - val_loss: 1.0858 - val_acc: 0.4047\n",
      "Epoch 14/50\n",
      "2307/2307 [==============================] - 0s 151us/step - loss: 1.0848 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4047\n",
      "Epoch 15/50\n",
      "2307/2307 [==============================] - 0s 187us/step - loss: 1.0847 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 16/50\n",
      "2307/2307 [==============================] - 0s 176us/step - loss: 1.0846 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 17/50\n",
      "2307/2307 [==============================] - 1s 218us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 18/50\n",
      "2307/2307 [==============================] - 0s 173us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 19/50\n",
      "2307/2307 [==============================] - 0s 156us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 20/50\n",
      "2307/2307 [==============================] - 0s 134us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 21/50\n",
      "2307/2307 [==============================] - 0s 146us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0854 - val_acc: 0.4047\n",
      "Epoch 22/50\n",
      "2307/2307 [==============================] - 0s 178us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 23/50\n",
      "2307/2307 [==============================] - 0s 174us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 24/50\n",
      "2307/2307 [==============================] - 0s 158us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 25/50\n",
      "2307/2307 [==============================] - 0s 147us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 26/50\n",
      "2307/2307 [==============================] - 0s 173us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 27/50\n",
      "2307/2307 [==============================] - 0s 192us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 28/50\n",
      "2307/2307 [==============================] - 0s 149us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 29/50\n",
      "2307/2307 [==============================] - 0s 140us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 30/50\n",
      "2307/2307 [==============================] - 0s 176us/step - loss: 1.0846 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 31/50\n",
      "2307/2307 [==============================] - 0s 182us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 32/50\n",
      "2307/2307 [==============================] - 0s 181us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 33/50\n",
      "2307/2307 [==============================] - 0s 135us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 34/50\n",
      "2307/2307 [==============================] - 0s 144us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 35/50\n",
      "2307/2307 [==============================] - 0s 170us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 36/50\n",
      "2307/2307 [==============================] - 0s 157us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 37/50\n",
      "2307/2307 [==============================] - 0s 134us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 38/50\n",
      "2307/2307 [==============================] - 0s 136us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 39/50\n",
      "2307/2307 [==============================] - 0s 130us/step - loss: 1.0845 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 40/50\n",
      "2307/2307 [==============================] - 0s 138us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0852 - val_acc: 0.4047\n",
      "Epoch 41/50\n",
      "2307/2307 [==============================] - 0s 138us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0856 - val_acc: 0.4047\n",
      "Epoch 42/50\n",
      "2307/2307 [==============================] - 0s 134us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0854 - val_acc: 0.4047\n",
      "Epoch 43/50\n",
      "2307/2307 [==============================] - 0s 130us/step - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0851 - val_acc: 0.4047\n",
      "Epoch 44/50\n",
      "2307/2307 [==============================] - 0s 132us/step - loss: 1.0846 - acc: 0.4114 - val_loss: 1.0850 - val_acc: 0.4047\n",
      "Epoch 45/50\n",
      "2307/2307 [==============================] - 0s 143us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 46/50\n",
      "2307/2307 [==============================] - 0s 136us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 47/50\n",
      "2307/2307 [==============================] - 0s 141us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0854 - val_acc: 0.4047\n",
      "Epoch 48/50\n",
      "2307/2307 [==============================] - 0s 133us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0854 - val_acc: 0.4047\n",
      "Epoch 49/50\n",
      "2307/2307 [==============================] - 0s 132us/step - loss: 1.0842 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n",
      "Epoch 50/50\n",
      "2307/2307 [==============================] - 0s 131us/step - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0853 - val_acc: 0.4047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4bce3f98>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train.values, y_train, epochs=50, validation_split=.1, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 0s 138us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0890361503952193, 0.40249609910009804]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test.values, y_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 3, kernel_initializer='uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CLEAN_EDIT_model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns.to_series()[\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  signal_x\n",
       "0     stay\n",
       "1     stay\n",
       "2     stay\n",
       "3     stay\n",
       "4     stay"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.drop(df.columns.to_series()[\"retweet_from\": \"zoo\"], axis=1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_from</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>encoded_sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abort</th>\n",
       "      <th>aborted</th>\n",
       "      <th>...</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>assuming acceleration of to but in a comfortab...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>is capable of transporting satellite to orbit ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yup</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>part</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>fly to most place on earth in under min and an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   retweet_from  tweet_length  encoded_sentiment  polarity  \\\n",
       "0           137           105                  1  0.366667   \n",
       "1            64           113                  1  0.200000   \n",
       "2           137             6                  0  0.000000   \n",
       "3           137             7                  0  0.000000   \n",
       "4           137            96                  1  0.650000   \n",
       "\n",
       "                                               tweet  ability  able  aboard  \\\n",
       "0  assuming acceleration of to but in a comfortab...      0.0   0.0     0.0   \n",
       "1  is capable of transporting satellite to orbit ...      0.0   0.0     0.0   \n",
       "2                                                yup      0.0   0.0     0.0   \n",
       "3                                               part      0.0   0.0     0.0   \n",
       "4  fly to most place on earth in under min and an...      0.0   0.0     0.0   \n",
       "\n",
       "   abort  aborted ...   you  your  yours  yourself   yr  yup  zero  zip  zone  \\\n",
       "0    0.0      0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0   \n",
       "1    0.0      0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0   \n",
       "2    0.0      0.0 ...   0.0   0.0    0.0       0.0  0.0  1.0   0.0  0.0   0.0   \n",
       "3    0.0      0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0   \n",
       "4    0.0      0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0   \n",
       "\n",
       "   zoo  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 3857 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(df.columns.to_series()[\"signal_x\"], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = x.drop(x.columns.to_series()[\"ability\": \"zoo\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = x.drop(x.columns.to_series()[\"retweet_from\": \"tweet\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abort</th>\n",
       "      <th>aborted</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>...</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  aboard  abort  aborted  about  above  absolutely  absorb  \\\n",
       "0      0.0   0.0     0.0    0.0      0.0    0.0    0.0         0.0     0.0   \n",
       "1      0.0   0.0     0.0    0.0      0.0    0.0    0.0         0.0     0.0   \n",
       "2      0.0   0.0     0.0    0.0      0.0    0.0    0.0         0.0     0.0   \n",
       "3      0.0   0.0     0.0    0.0      0.0    0.0    0.0         0.0     0.0   \n",
       "4      0.0   0.0     0.0    0.0      0.0    0.0    0.0         0.0     0.0   \n",
       "\n",
       "   absorbed ...   you  your  yours  yourself   yr  yup  zero  zip  zone  zoo  \n",
       "0       0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0  0.0  \n",
       "1       0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0  0.0  \n",
       "2       0.0 ...   0.0   0.0    0.0       0.0  0.0  1.0   0.0  0.0   0.0  0.0  \n",
       "3       0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0  0.0  \n",
       "4       0.0 ...   0.0   0.0    0.0       0.0  0.0  0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 3852 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03053431, -0.02636362, -0.00967677, ...,  0.02809921,\n",
       "         0.01081785, -0.01844455],\n",
       "       [-0.0589778 , -0.11301196,  0.09692554, ...,  0.00336811,\n",
       "        -0.02342973, -0.01792601],\n",
       "       [-0.00220386,  0.04452286, -0.08819209, ..., -0.0975277 ,\n",
       "        -0.01884974,  0.01580084],\n",
       "       ...,\n",
       "       [-0.01966206, -0.00474363, -0.04375533, ...,  0.05753096,\n",
       "         0.01697662,  0.03687633],\n",
       "       [-0.02563249, -0.00983638, -0.01822253, ..., -0.02616331,\n",
       "        -0.02219404, -0.10793007],\n",
       "       [-0.02191234, -0.00816946, -0.0320238 , ..., -0.02856638,\n",
       "         0.02187234,  0.03395731]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca = pca.transform(tfidf_data)\n",
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1761 samples, validate on 441 samples\n",
      "Epoch 1/100\n",
      "1761/1761 [==============================] - 1s 329us/step - loss: 0.6343 - acc: 0.6667 - val_loss: 0.6335 - val_acc: 0.6667\n",
      "Epoch 2/100\n",
      "1761/1761 [==============================] - 0s 120us/step - loss: 0.6309 - acc: 0.6667 - val_loss: 0.6330 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.6294 - acc: 0.6667 - val_loss: 0.6327 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.6284 - acc: 0.6669 - val_loss: 0.6324 - val_acc: 0.6674\n",
      "Epoch 5/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.6263 - acc: 0.6678 - val_loss: 0.6319 - val_acc: 0.6674\n",
      "Epoch 6/100\n",
      "1761/1761 [==============================] - 0s 105us/step - loss: 0.6248 - acc: 0.6703 - val_loss: 0.6318 - val_acc: 0.6644\n",
      "Epoch 7/100\n",
      "1761/1761 [==============================] - 0s 109us/step - loss: 0.6234 - acc: 0.6725 - val_loss: 0.6313 - val_acc: 0.6659\n",
      "Epoch 8/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6228 - acc: 0.6735 - val_loss: 0.6330 - val_acc: 0.6606\n",
      "Epoch 9/100\n",
      "1761/1761 [==============================] - 0s 110us/step - loss: 0.6217 - acc: 0.6722 - val_loss: 0.6315 - val_acc: 0.6644\n",
      "Epoch 10/100\n",
      "1761/1761 [==============================] - 0s 106us/step - loss: 0.6214 - acc: 0.6729 - val_loss: 0.6315 - val_acc: 0.6614\n",
      "Epoch 11/100\n",
      "1761/1761 [==============================] - 0s 118us/step - loss: 0.6208 - acc: 0.6733 - val_loss: 0.6339 - val_acc: 0.6538\n",
      "Epoch 12/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6203 - acc: 0.6735 - val_loss: 0.6336 - val_acc: 0.6523\n",
      "Epoch 13/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.6198 - acc: 0.6759 - val_loss: 0.6320 - val_acc: 0.6606\n",
      "Epoch 14/100\n",
      "1761/1761 [==============================] - 0s 113us/step - loss: 0.6200 - acc: 0.6756 - val_loss: 0.6331 - val_acc: 0.6553\n",
      "Epoch 15/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6197 - acc: 0.6746 - val_loss: 0.6343 - val_acc: 0.6515\n",
      "Epoch 16/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.6190 - acc: 0.6735 - val_loss: 0.6324 - val_acc: 0.6591\n",
      "Epoch 17/100\n",
      "1761/1761 [==============================] - 0s 128us/step - loss: 0.6190 - acc: 0.6740 - val_loss: 0.6344 - val_acc: 0.6538\n",
      "Epoch 18/100\n",
      "1761/1761 [==============================] - 0s 133us/step - loss: 0.6189 - acc: 0.6748 - val_loss: 0.6342 - val_acc: 0.6538\n",
      "Epoch 19/100\n",
      "1761/1761 [==============================] - 0s 130us/step - loss: 0.6187 - acc: 0.6754 - val_loss: 0.6351 - val_acc: 0.6531\n",
      "Epoch 20/100\n",
      "1761/1761 [==============================] - 0s 124us/step - loss: 0.6182 - acc: 0.6765 - val_loss: 0.6365 - val_acc: 0.6508\n",
      "Epoch 21/100\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 0.6180 - acc: 0.6731 - val_loss: 0.6354 - val_acc: 0.6546\n",
      "Epoch 22/100\n",
      "1761/1761 [==============================] - 0s 123us/step - loss: 0.6179 - acc: 0.6735 - val_loss: 0.6350 - val_acc: 0.6538\n",
      "Epoch 23/100\n",
      "1761/1761 [==============================] - 0s 109us/step - loss: 0.6176 - acc: 0.6750 - val_loss: 0.6363 - val_acc: 0.6546\n",
      "Epoch 24/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.6171 - acc: 0.6754 - val_loss: 0.6359 - val_acc: 0.6538\n",
      "Epoch 25/100\n",
      "1761/1761 [==============================] - 0s 137us/step - loss: 0.6170 - acc: 0.6763 - val_loss: 0.6357 - val_acc: 0.6561\n",
      "Epoch 26/100\n",
      "1761/1761 [==============================] - 0s 139us/step - loss: 0.6165 - acc: 0.6756 - val_loss: 0.6376 - val_acc: 0.6515\n",
      "Epoch 27/100\n",
      "1761/1761 [==============================] - 0s 134us/step - loss: 0.6164 - acc: 0.6754 - val_loss: 0.6354 - val_acc: 0.6584\n",
      "Epoch 28/100\n",
      "1761/1761 [==============================] - 0s 134us/step - loss: 0.6160 - acc: 0.6767 - val_loss: 0.6351 - val_acc: 0.6591\n",
      "Epoch 29/100\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 0.6153 - acc: 0.6756 - val_loss: 0.6391 - val_acc: 0.6531\n",
      "Epoch 30/100\n",
      "1761/1761 [==============================] - 0s 122us/step - loss: 0.6149 - acc: 0.6775 - val_loss: 0.6372 - val_acc: 0.6546\n",
      "Epoch 31/100\n",
      "1761/1761 [==============================] - 0s 110us/step - loss: 0.6149 - acc: 0.6775 - val_loss: 0.6385 - val_acc: 0.6538\n",
      "Epoch 32/100\n",
      "1761/1761 [==============================] - 0s 124us/step - loss: 0.6144 - acc: 0.6765 - val_loss: 0.6403 - val_acc: 0.6531\n",
      "Epoch 33/100\n",
      "1761/1761 [==============================] - 0s 135us/step - loss: 0.6136 - acc: 0.6780 - val_loss: 0.6386 - val_acc: 0.6546\n",
      "Epoch 34/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.6133 - acc: 0.6782 - val_loss: 0.6384 - val_acc: 0.6591\n",
      "Epoch 35/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.6126 - acc: 0.6780 - val_loss: 0.6421 - val_acc: 0.6531\n",
      "Epoch 36/100\n",
      "1761/1761 [==============================] - 0s 119us/step - loss: 0.6128 - acc: 0.6767 - val_loss: 0.6419 - val_acc: 0.6546\n",
      "Epoch 37/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6121 - acc: 0.6795 - val_loss: 0.6427 - val_acc: 0.6531\n",
      "Epoch 38/100\n",
      "1761/1761 [==============================] - 0s 109us/step - loss: 0.6119 - acc: 0.6797 - val_loss: 0.6428 - val_acc: 0.6531\n",
      "Epoch 39/100\n",
      "1761/1761 [==============================] - 0s 112us/step - loss: 0.6111 - acc: 0.6812 - val_loss: 0.6427 - val_acc: 0.6515\n",
      "Epoch 40/100\n",
      "1761/1761 [==============================] - 0s 105us/step - loss: 0.6105 - acc: 0.6809 - val_loss: 0.6437 - val_acc: 0.6531\n",
      "Epoch 41/100\n",
      "1761/1761 [==============================] - 0s 102us/step - loss: 0.6099 - acc: 0.6807 - val_loss: 0.6448 - val_acc: 0.6531\n",
      "Epoch 42/100\n",
      "1761/1761 [==============================] - 0s 115us/step - loss: 0.6097 - acc: 0.6803 - val_loss: 0.6434 - val_acc: 0.6523\n",
      "Epoch 43/100\n",
      "1761/1761 [==============================] - 0s 148us/step - loss: 0.6090 - acc: 0.6822 - val_loss: 0.6434 - val_acc: 0.6531\n",
      "Epoch 44/100\n",
      "1761/1761 [==============================] - 0s 167us/step - loss: 0.6085 - acc: 0.6828 - val_loss: 0.6420 - val_acc: 0.6584\n",
      "Epoch 45/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6085 - acc: 0.6822 - val_loss: 0.6428 - val_acc: 0.6576\n",
      "Epoch 46/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.6074 - acc: 0.6841 - val_loss: 0.6449 - val_acc: 0.6561\n",
      "Epoch 47/100\n",
      "1761/1761 [==============================] - 0s 110us/step - loss: 0.6070 - acc: 0.6843 - val_loss: 0.6455 - val_acc: 0.6531\n",
      "Epoch 48/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.6065 - acc: 0.6845 - val_loss: 0.6460 - val_acc: 0.6531\n",
      "Epoch 49/100\n",
      "1761/1761 [==============================] - 0s 104us/step - loss: 0.6055 - acc: 0.6854 - val_loss: 0.6448 - val_acc: 0.6576\n",
      "Epoch 50/100\n",
      "1761/1761 [==============================] - 0s 104us/step - loss: 0.6048 - acc: 0.6867 - val_loss: 0.6466 - val_acc: 0.6546\n",
      "Epoch 51/100\n",
      "1761/1761 [==============================] - 0s 106us/step - loss: 0.6043 - acc: 0.6858 - val_loss: 0.6490 - val_acc: 0.6531\n",
      "Epoch 52/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.6035 - acc: 0.6864 - val_loss: 0.6480 - val_acc: 0.6523\n",
      "Epoch 53/100\n",
      "1761/1761 [==============================] - 0s 102us/step - loss: 0.6032 - acc: 0.6871 - val_loss: 0.6473 - val_acc: 0.6568\n",
      "Epoch 54/100\n",
      "1761/1761 [==============================] - 0s 112us/step - loss: 0.6021 - acc: 0.6858 - val_loss: 0.6477 - val_acc: 0.6599\n",
      "Epoch 55/100\n",
      "1761/1761 [==============================] - 0s 114us/step - loss: 0.6013 - acc: 0.6886 - val_loss: 0.6532 - val_acc: 0.6546\n",
      "Epoch 56/100\n",
      "1761/1761 [==============================] - 0s 110us/step - loss: 0.6009 - acc: 0.6875 - val_loss: 0.6554 - val_acc: 0.6515\n",
      "Epoch 57/100\n",
      "1761/1761 [==============================] - 0s 130us/step - loss: 0.6004 - acc: 0.6881 - val_loss: 0.6521 - val_acc: 0.6531\n",
      "Epoch 58/100\n",
      "1761/1761 [==============================] - 0s 138us/step - loss: 0.5989 - acc: 0.6911 - val_loss: 0.6516 - val_acc: 0.6546\n",
      "Epoch 59/100\n",
      "1761/1761 [==============================] - 0s 133us/step - loss: 0.5982 - acc: 0.6901 - val_loss: 0.6532 - val_acc: 0.6538\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 0s 128us/step - loss: 0.5975 - acc: 0.6894 - val_loss: 0.6546 - val_acc: 0.6531\n",
      "Epoch 61/100\n",
      "1761/1761 [==============================] - 0s 125us/step - loss: 0.5969 - acc: 0.6913 - val_loss: 0.6528 - val_acc: 0.6576\n",
      "Epoch 62/100\n",
      "1761/1761 [==============================] - 0s 127us/step - loss: 0.5954 - acc: 0.6926 - val_loss: 0.6518 - val_acc: 0.6576\n",
      "Epoch 63/100\n",
      "1761/1761 [==============================] - 0s 133us/step - loss: 0.5958 - acc: 0.6913 - val_loss: 0.6539 - val_acc: 0.6523\n",
      "Epoch 64/100\n",
      "1761/1761 [==============================] - 0s 116us/step - loss: 0.5932 - acc: 0.6926 - val_loss: 0.6610 - val_acc: 0.6455\n",
      "Epoch 65/100\n",
      "1761/1761 [==============================] - 0s 114us/step - loss: 0.5931 - acc: 0.6937 - val_loss: 0.6589 - val_acc: 0.6531\n",
      "Epoch 66/100\n",
      "1761/1761 [==============================] - 0s 119us/step - loss: 0.5915 - acc: 0.6928 - val_loss: 0.6569 - val_acc: 0.6531\n",
      "Epoch 67/100\n",
      "1761/1761 [==============================] - 0s 115us/step - loss: 0.5916 - acc: 0.6926 - val_loss: 0.6619 - val_acc: 0.6485\n",
      "Epoch 68/100\n",
      "1761/1761 [==============================] - 0s 114us/step - loss: 0.5902 - acc: 0.6934 - val_loss: 0.6564 - val_acc: 0.6546\n",
      "Epoch 69/100\n",
      "1761/1761 [==============================] - 0s 114us/step - loss: 0.5898 - acc: 0.6943 - val_loss: 0.6637 - val_acc: 0.6523\n",
      "Epoch 70/100\n",
      "1761/1761 [==============================] - 0s 123us/step - loss: 0.5885 - acc: 0.6947 - val_loss: 0.6604 - val_acc: 0.6538\n",
      "Epoch 71/100\n",
      "1761/1761 [==============================] - 0s 116us/step - loss: 0.5871 - acc: 0.6960 - val_loss: 0.6612 - val_acc: 0.6538\n",
      "Epoch 72/100\n",
      "1761/1761 [==============================] - 0s 116us/step - loss: 0.5859 - acc: 0.6971 - val_loss: 0.6648 - val_acc: 0.6531\n",
      "Epoch 73/100\n",
      "1761/1761 [==============================] - 0s 119us/step - loss: 0.5854 - acc: 0.6964 - val_loss: 0.6687 - val_acc: 0.6463\n",
      "Epoch 74/100\n",
      "1761/1761 [==============================] - 0s 113us/step - loss: 0.5832 - acc: 0.6973 - val_loss: 0.6642 - val_acc: 0.6561\n",
      "Epoch 75/100\n",
      "1761/1761 [==============================] - 0s 118us/step - loss: 0.5834 - acc: 0.6964 - val_loss: 0.6696 - val_acc: 0.6515\n",
      "Epoch 76/100\n",
      "1761/1761 [==============================] - 0s 118us/step - loss: 0.5820 - acc: 0.6977 - val_loss: 0.6724 - val_acc: 0.6478\n",
      "Epoch 77/100\n",
      "1761/1761 [==============================] - 0s 129us/step - loss: 0.5803 - acc: 0.6981 - val_loss: 0.6707 - val_acc: 0.6493\n",
      "Epoch 78/100\n",
      "1761/1761 [==============================] - 0s 141us/step - loss: 0.5785 - acc: 0.7023 - val_loss: 0.6756 - val_acc: 0.6447\n",
      "Epoch 79/100\n",
      "1761/1761 [==============================] - 0s 132us/step - loss: 0.5784 - acc: 0.7024 - val_loss: 0.6754 - val_acc: 0.6485\n",
      "Epoch 80/100\n",
      "1761/1761 [==============================] - 0s 109us/step - loss: 0.5777 - acc: 0.6992 - val_loss: 0.6717 - val_acc: 0.6531\n",
      "Epoch 81/100\n",
      "1761/1761 [==============================] - 0s 144us/step - loss: 0.5761 - acc: 0.6996 - val_loss: 0.6804 - val_acc: 0.6432\n",
      "Epoch 82/100\n",
      "1761/1761 [==============================] - 0s 138us/step - loss: 0.5762 - acc: 0.7028 - val_loss: 0.6794 - val_acc: 0.6447\n",
      "Epoch 83/100\n",
      "1761/1761 [==============================] - 0s 113us/step - loss: 0.5741 - acc: 0.7036 - val_loss: 0.6804 - val_acc: 0.6463\n",
      "Epoch 84/100\n",
      "1761/1761 [==============================] - 0s 112us/step - loss: 0.5731 - acc: 0.7019 - val_loss: 0.6802 - val_acc: 0.6470\n",
      "Epoch 85/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.5721 - acc: 0.7028 - val_loss: 0.6756 - val_acc: 0.6508\n",
      "Epoch 86/100\n",
      "1761/1761 [==============================] - 0s 117us/step - loss: 0.5707 - acc: 0.7068 - val_loss: 0.6837 - val_acc: 0.6447\n",
      "Epoch 87/100\n",
      "1761/1761 [==============================] - 0s 110us/step - loss: 0.5693 - acc: 0.7028 - val_loss: 0.6937 - val_acc: 0.6425\n",
      "Epoch 88/100\n",
      "1761/1761 [==============================] - 0s 100us/step - loss: 0.5690 - acc: 0.7058 - val_loss: 0.6846 - val_acc: 0.6463\n",
      "Epoch 89/100\n",
      "1761/1761 [==============================] - 0s 108us/step - loss: 0.5686 - acc: 0.7085 - val_loss: 0.6886 - val_acc: 0.6470\n",
      "Epoch 90/100\n",
      "1761/1761 [==============================] - 0s 107us/step - loss: 0.5685 - acc: 0.7055 - val_loss: 0.6890 - val_acc: 0.6455\n",
      "Epoch 91/100\n",
      "1761/1761 [==============================] - 0s 109us/step - loss: 0.5666 - acc: 0.7066 - val_loss: 0.6866 - val_acc: 0.6493\n",
      "Epoch 92/100\n",
      "1761/1761 [==============================] - 0s 116us/step - loss: 0.5656 - acc: 0.7068 - val_loss: 0.7000 - val_acc: 0.6372\n",
      "Epoch 93/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.5651 - acc: 0.7074 - val_loss: 0.6949 - val_acc: 0.6410\n",
      "Epoch 94/100\n",
      "1761/1761 [==============================] - 0s 111us/step - loss: 0.5630 - acc: 0.7087 - val_loss: 0.6997 - val_acc: 0.6410\n",
      "Epoch 95/100\n",
      "1761/1761 [==============================] - 0s 134us/step - loss: 0.5635 - acc: 0.7089 - val_loss: 0.7125 - val_acc: 0.6410\n",
      "Epoch 96/100\n",
      "1761/1761 [==============================] - 0s 142us/step - loss: 0.5618 - acc: 0.7098 - val_loss: 0.6997 - val_acc: 0.6395\n",
      "Epoch 97/100\n",
      "1761/1761 [==============================] - 0s 143us/step - loss: 0.5608 - acc: 0.7121 - val_loss: 0.7002 - val_acc: 0.6417\n",
      "Epoch 98/100\n",
      "1761/1761 [==============================] - 0s 105us/step - loss: 0.5592 - acc: 0.7113 - val_loss: 0.6964 - val_acc: 0.6485\n",
      "Epoch 99/100\n",
      "1761/1761 [==============================] - 0s 113us/step - loss: 0.5600 - acc: 0.7106 - val_loss: 0.7025 - val_acc: 0.6417\n",
      "Epoch 100/100\n",
      "1761/1761 [==============================] - 0s 119us/step - loss: 0.5585 - acc: 0.7113 - val_loss: 0.7042 - val_acc: 0.6417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a419ca5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 3, kernel_initializer='uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100, validation_split=0.1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tfidf_data.values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = sentiment_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_data, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1761 samples, validate on 441 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'been done'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-20602d5af8b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'been done'"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 3, kernel_initializer='uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100, validation_split=0.1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
